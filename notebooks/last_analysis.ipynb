{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU:  cuda:0\n",
      "Running on GPU:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/mattisdo/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU:  cuda:0\n",
      "Running on GPU:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/mattisdo/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/users/mattisdo/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/users/mattisdo/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/users/mattisdo/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "# import line_profiler as lp \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, functional\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from model import *\n",
    "from model2D import *\n",
    "from datagen import *\n",
    "from analysis import *\n",
    "from datagen2D import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on GPU: \", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "torch.set_default_device(device)\n",
    "# torch.cuda.synchronize()\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4096\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "train1 = False\n",
    "\n",
    "# Run multiple times to see the effect of the random initialization\n",
    "if train1:\n",
    "    model = torch_RNN_full_manual(input_size,200,output_size,hidden_size,lr=0.01,irnn=True,outputnn=True,bias=True,activation=True)\n",
    "    _ = model.train_gradual(epochs=1000)\n",
    "    model.plot_losses(average=30)\n",
    "    # model.plot_accs()\n",
    "    print(f\"Init weights: Wh = {model.Wh_init}, Wx = {model.Wx_init}\")\n",
    "    # print(\"Guess on the first 15 training data: \",model(data[0:15]))\n",
    "    print(\"Weight of the hidden layer Wh: \",model.rnn.weight_hh_l0, \" Weight of the input layer Wx: \",model.rnn.weight_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datamodel(Dataset):\n",
    "    def __init__(self,time_pos_points,labels):\n",
    "        self.x = time_pos_points\n",
    "        self.y = labels\n",
    "    def __len__(self): \n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, ix):\n",
    "        return self.x[ix], self.y[ix]\n",
    "\n",
    "n_data = 1000\n",
    "t_steps = 10\n",
    "\n",
    "data,labels = datagen_full_sum_normal(n_data,t_steps,normalize=True)\n",
    "# data,labels = datagen_timewise_labels(n_data,t_steps,2)\n",
    "# print(data[1],labels[1])\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "training_data = Datamodel(data,labels)\n",
    "training_loader = torch.utils.data.DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess on the first 15 training data:  tensor([0.4809, 0.7412, 0.5998, 0.7195, 0.9161, 0.5020, 0.4521, 0.5075, 0.6997,\n",
      "        0.5000, 0.6807, 0.9193, 0.5330, 0.8584, 0.6923], device='cuda:0',\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a 'cuda' device type for generator but found 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model2 \u001b[39m=\u001b[39m torch_RNN_full_manual(input_size,t_steps,output_size,hidden_size,lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m,irnn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,outputnn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,Wx_normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,activation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGuess on the first 15 training data: \u001b[39m\u001b[39m\"\u001b[39m, model2(data[\u001b[39m0\u001b[39m:\u001b[39m15\u001b[39m]))\n\u001b[0;32m---> 11\u001b[0m _ \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mtrain_loader(training_loader,epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m model2\u001b[39m.\u001b[39mplot_losses(average\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# model2.plot_accs()\u001b[39;00m\n",
      "File \u001b[0;32m~/RNN-circles/RNN-Adding-Problem-Representations/notebooks/../src/model.py:287\u001b[0m, in \u001b[0;36mtorch_RNN_full_manual.train_loader\u001b[0;34m(self, loader, epochs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_loader\u001b[39m(\u001b[39mself\u001b[39m, loader, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[1;32m    286\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 287\u001b[0m         \u001b[39mfor\u001b[39;00m i,(inputs,labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(loader):\n\u001b[1;32m    288\u001b[0m             loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(inputs,labels)\n\u001b[1;32m    289\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1084\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1082\u001b[0m _utils\u001b[39m.\u001b[39msignal_handling\u001b[39m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[1;32m   1083\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_pids_set \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset(loader, first_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1117\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[39m# prime the prefetch loop\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_factor \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers):\n\u001b[0;32m-> 1117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_put_index()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1351\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_factor \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers\n\u001b[1;32m   1350\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1351\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()\n\u001b[1;32m   1352\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:623\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 623\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/sampler.py:254\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m batch \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    253\u001b[0m idx_in_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 254\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler:\n\u001b[1;32m    255\u001b[0m     batch[idx_in_batch] \u001b[39m=\u001b[39m idx\n\u001b[1;32m    256\u001b[0m     idx_in_batch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/data/sampler.py:132\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[0;32m--> 132\u001b[0m         \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    133\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected a 'cuda' device type for generator but found 'cpu'"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "train2 = True\n",
    "\n",
    "if train2:\n",
    "    # model2 = torch_RNN1(input_size,t_steps,output_size,hidden_size,lr=0.01,irnn=True,outputnn=False,Wx_normalize=True)\n",
    "    model2 = torch_RNN_full_manual(input_size,t_steps,output_size,hidden_size,lr=0.001,irnn=False,outputnn=False,Wx_normalize=False,activation=False)\n",
    "    print(\"Guess on the first 15 training data: \", model2(data[0:15]))\n",
    "    _ = model2.train_loader(training_loader,epochs=300)\n",
    "    model2.plot_losses(average=30)\n",
    "    # model2.plot_accs()\n",
    "    print(\"Guess on the first 15 training data: \", model2(data[0:15]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
